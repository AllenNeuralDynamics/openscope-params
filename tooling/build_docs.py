"""Generate documentation pages for packs and schemas.

Outputs:
- docs/reference/packs.md
- docs/reference/schemas.md
- docs/reference/schemas_html/** (HTML generated via json-schema-for-humans, if installed)

This script is intended to be run from the repo root:
  python .\tooling\build_docs.py
"""

from __future__ import annotations

import json
import os
import subprocess
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Iterable


REPO_ROOT = Path(__file__).resolve().parents[1]
PACKS_DIR = REPO_ROOT / "packs"
TOOLING_DIR = REPO_ROOT / "tooling"
DOCS_REF_DIR = REPO_ROOT / "docs" / "reference"
SCHEMA_HTML_DIR = DOCS_REF_DIR / "schemas_html"


@dataclass(frozen=True)
class DocItem:
    title: str
    rel_path_posix: str
    description: str | None


@dataclass(frozen=True)
class PackDoc:
    pack_name: str
    pack_rel_dir_posix: str
    pack_description: str | None
    items: list[DocItem]


def _iter_json_files(root: Path) -> Iterable[Path]:
    yield from sorted(p for p in root.rglob("*.json") if p.is_file())


def _read_json(path: Path) -> dict[str, Any]:
    with path.open("r", encoding="utf-8") as f:
        return json.load(f)


def _posix_rel(path: Path, base: Path) -> str:
    return path.relative_to(base).as_posix()


def _github_file_url(*, repo_url: str, rel_path_posix: str, ref: str = "main", repo_subdir: str | None = None) -> str:
    repo_url = repo_url.rstrip("/")
    if repo_subdir:
        repo_subdir = repo_subdir.strip("/")
        return f"{repo_url}/blob/{ref}/{repo_subdir}/{rel_path_posix}"
    return f"{repo_url}/blob/{ref}/{rel_path_posix}"


def _extract_title_and_description(data: dict[str, Any], fallback_title: str) -> tuple[str, str | None]:
    title = data.get("title")
    if isinstance(title, str) and title.strip():
        title_str = title.strip()
    else:
        title_str = fallback_title

    description = data.get("description")
    if isinstance(description, str) and description.strip():
        desc_str: str | None = description.strip()
    else:
        desc_str = None

    return title_str, desc_str


def _group_by_first_segment(items: list[DocItem]) -> dict[str, list[DocItem]]:
    grouped: dict[str, list[DocItem]] = {}
    for item in items:
        first = item.rel_path_posix.split("/", 1)[0]
        grouped.setdefault(first, []).append(item)
    return grouped


def _read_pack_description(pack_dir: Path) -> str | None:
    readme = pack_dir / "README.md"
    if not readme.exists():
        return None

    text = readme.read_text(encoding="utf-8").strip()
    if not text:
        return None

    # Very small markdown heuristic: remove leading H1 line if present and take the first paragraph.
    lines = [ln.rstrip() for ln in text.splitlines()]
    if lines and lines[0].lstrip().startswith("#"):
        lines = lines[1:]

    paragraph: list[str] = []
    for ln in lines:
        if not ln.strip():
            if paragraph:
                break
            continue
        paragraph.append(ln.strip())

    return " ".join(paragraph).strip() or None


def _render_packs_md(*, packs_dir: Path, repo_url: str, repo_ref: str, repo_subdir: str | None) -> str:
    # Build per-pack sections (packs/<pack>/*.json).
    pack_docs: list[PackDoc] = []
    for pack_dir in sorted(p for p in packs_dir.iterdir() if p.is_dir() and not p.name.startswith(".")):
        items: list[DocItem] = []
        for json_path in sorted(p for p in pack_dir.glob("*.json") if p.is_file()):
            data = _read_json(json_path)
            title, desc = _extract_title_and_description(data, fallback_title=json_path.stem)
            items.append(DocItem(title=title, rel_path_posix=_posix_rel(json_path, REPO_ROOT), description=desc))

        if not items:
            continue

        pack_docs.append(
            PackDoc(
                pack_name=pack_dir.name,
                pack_rel_dir_posix=_posix_rel(pack_dir, REPO_ROOT),
                pack_description=_read_pack_description(pack_dir),
                items=items,
            )
        )

    lines: list[str] = ["# Packs (reference)", ""]
    lines.append("Generated by `tooling/build_docs.py`. Do not edit by hand.")
    lines.append("")
    lines.append("Each section corresponds to a pack under `packs/<pack_name>/`.")
    lines.append("")

    for pack in pack_docs:
        lines.append(f"## {pack.pack_name}")
        lines.append("")
        pack_dir_url = _github_file_url(repo_url=repo_url, rel_path_posix=pack.pack_rel_dir_posix, ref=repo_ref, repo_subdir=repo_subdir)
        lines.append(f"Pack directory: [`{pack.pack_rel_dir_posix}`]({pack_dir_url})")
        if pack.pack_description:
            lines.append("")
            lines.append(pack.pack_description)
        lines.append("")

        for item in pack.items:
            file_url = _github_file_url(repo_url=repo_url, rel_path_posix=item.rel_path_posix, ref=repo_ref, repo_subdir=repo_subdir)
            display_name = item.rel_path_posix.split("/", 2)[-1]
            desc = f" — {item.description}" if item.description else ""
            lines.append(f"- [`{display_name}`]({file_url}){desc}")

        lines.append("")

    return "\n".join(lines).rstrip() + "\n"


def _write_markdown(path: Path, content: str) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(content, encoding="utf-8")


def _render_items_md(
    *,
    heading: str,
    items: list[DocItem],
    repo_url: str,
    repo_ref: str,
    repo_subdir: str | None,
) -> str:
    grouped = _group_by_first_segment(items)

    lines: list[str] = [f"# {heading}", ""]
    lines.append(f"Generated by `tooling/build_docs.py`. Do not edit by hand.")
    lines.append("")

    for group_name in sorted(grouped.keys()):
        lines.append(f"## {group_name}")
        lines.append("")
        for item in grouped[group_name]:
            file_url = _github_file_url(repo_url=repo_url, rel_path_posix=item.rel_path_posix, ref=repo_ref, repo_subdir=repo_subdir)
            desc = f" — {item.description}" if item.description else ""
            lines.append(f"- [`{item.rel_path_posix}`]({file_url}){desc}")
        lines.append("")

    return "\n".join(lines).rstrip() + "\n"


def _has_json_schema_for_humans() -> bool:
    try:
        import json_schema_for_humans  # noqa: F401

        return True
    except Exception:
        return False


def _generate_schema_html(schema_files: list[Path]) -> bool:
    """Generate HTML docs for each schema file using json-schema-for-humans.

    We call the CLI for compatibility across versions.
    """

    if not _has_json_schema_for_humans():
        print("INFO: json-schema-for-humans not installed; skipping schema HTML generation.")
        return False

    SCHEMA_HTML_DIR.mkdir(parents=True, exist_ok=True)

    for schema_path in schema_files:
        rel = _posix_rel(schema_path, TOOLING_DIR)
        out_dir = SCHEMA_HTML_DIR / Path(rel).with_suffix("")
        out_dir.mkdir(parents=True, exist_ok=True)

        # The CLI name is generate-schema-doc (installed by json-schema-for-humans).
        # Output is index.html in the output directory.
        cmd = [
            sys.executable,
            "-m",
            "json_schema_for_humans.generate",
            "--config",
            "{\"show_breadcrumbs\": true, \"copy_css\": true}",
            "--output",
            str(out_dir),
            str(schema_path),
        ]

        try:
            subprocess.run(cmd, check=True, cwd=str(REPO_ROOT), stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
        except subprocess.CalledProcessError as e:
            output = e.stdout.decode("utf-8", errors="replace") if e.stdout else str(e)
            print(f"WARN: Failed generating HTML for {rel}:\n{output}")
            return False

    return True


def main() -> int:
    repo_url = os.environ.get(
        "OPENSCOPE_PARAMS_REPO_URL",
        "https://github.com/AllenNeuralDynamics/openscope-community-predictive-processing",
    )
    repo_ref = os.environ.get("OPENSCOPE_PARAMS_REPO_REF", "main")
    repo_subdir_env = os.environ.get("OPENSCOPE_PARAMS_REPO_SUBDIR", "openscope-params")
    repo_subdir = repo_subdir_env.strip("/") if repo_subdir_env else None

    packs_md = _render_packs_md(packs_dir=PACKS_DIR, repo_url=repo_url, repo_ref=repo_ref, repo_subdir=repo_subdir)

    schemas: list[DocItem] = []
    schema_paths = sorted(TOOLING_DIR.glob("*.schema.json"))
    for s in schema_paths:
        data = _read_json(s)
        title, desc = _extract_title_and_description(data, fallback_title=s.stem)
        schemas.append(DocItem(title=title, rel_path_posix=_posix_rel(s, REPO_ROOT), description=desc))

    DOCS_REF_DIR.mkdir(parents=True, exist_ok=True)

    schemas_md = _render_items_md(
        heading="Schemas (reference)",
        items=schemas,
        repo_url=repo_url,
        repo_ref=repo_ref,
        repo_subdir=repo_subdir,
    )

    packs_md_path = DOCS_REF_DIR / "packs.md"
    schemas_md_path = DOCS_REF_DIR / "schemas.md"

    _write_markdown(packs_md_path, packs_md)
    _write_markdown(schemas_md_path, schemas_md)

    # Best-effort HTML generation.
    generated_html = _generate_schema_html(schema_paths)
    if generated_html:
        # Add a small hint section in schemas.md for the HTML pages.
        hint = (
            "\n## HTML schema docs (generated)\n\n"
            "This build also generated per-schema HTML under `docs/reference/schemas_html/` "
            "(published in the site as static files).\n"
        )
        _write_markdown(schemas_md_path, (schemas_md.rstrip() + hint + "\n"))

    print(f"Wrote {packs_md_path.relative_to(REPO_ROOT)}")
    print(f"Wrote {schemas_md_path.relative_to(REPO_ROOT)}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
